{"cells":[{"metadata":{"collapsed":false,"id":"54E1B4C7AED741DB8F3BDFC7F062BD20","scrolled":false},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense, LSTM, Dropout\n\nimport matplotlib.pyplot as plt\n\nimport glob, os\nimport seaborn as sns\nimport sys\n# from sklearn.preprocessing import MinMaxScale\n","execution_count":8,"outputs":[]},{"metadata":{"collapsed":false,"id":"ADDA3444608844DC89DA009CAEAAEE3B","scrolled":false},"cell_type":"code","source":"'''\r\n** 训练数据有8列：**\r\n\r\n- 日期 - 年: int\r\n- 日期 - 月: int\r\n- 日期 - 日: int， 时间跨度为2015年2月1日 - 2016年8月31日\r\n- 当日最高气温 - 摄氏度（下同）: float\r\n- 当日最低气温: float\r\n- 当日平均气温: float\r\n- 当日平均湿度: float\r\n- 输出：产值 - float\r\n预测数据没有输出部分，其他与预测一样。时间跨度为2016年9月1日 - 2016年11月30日\r\n数据来自于真实的工业场景，发布者已对其进行了脱敏处理。\r\n训练与预测都各自包含46组数据文件，每组数据代表不同数据源，组之间的温度与湿度信息一样而输出不同.\r\n本次实验仅对其中一组数据进行LSTM时间序列预测，其他数据同。\r\n'''\r\n# 加载数据文件——数据采集区1\r\ncolumns = ['YEAR','MONTH','DAY','TEMP_HIG','TEMP_COL','AVG_TEMP','AVG_WET','DATA_COL']\r\ndata = pd.read_csv('../input/industry/industry_timeseries/timeseries_train_data/1.csv', \r\n                      names=columns)\r\n# 展示前五个数据结果\r\ndata.head()","execution_count":9,"outputs":[{"output_type":"execute_result","metadata":{},"data":{"text/plain":"   YEAR  MONTH  DAY  TEMP_HIG  TEMP_COL  AVG_TEMP  AVG_WET    DATA_COL\n0  2015      2    1       1.9      -0.4    0.7875   75.000  907.177044\n1  2015      2    2       6.2      -3.9    1.7625   77.250  747.835779\n2  2015      2    3       7.8       2.0    4.2375   72.750  740.097015\n3  2015      2    4       8.5      -1.2    3.0375   65.875  760.081199\n4  2015      2    5       7.9      -3.6    1.8625   55.375  676.920858","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>YEAR</th>\n      <th>MONTH</th>\n      <th>DAY</th>\n      <th>TEMP_HIG</th>\n      <th>TEMP_COL</th>\n      <th>AVG_TEMP</th>\n      <th>AVG_WET</th>\n      <th>DATA_COL</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2015</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1.9</td>\n      <td>-0.4</td>\n      <td>0.7875</td>\n      <td>75.000</td>\n      <td>907.177044</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2015</td>\n      <td>2</td>\n      <td>2</td>\n      <td>6.2</td>\n      <td>-3.9</td>\n      <td>1.7625</td>\n      <td>77.250</td>\n      <td>747.835779</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2015</td>\n      <td>2</td>\n      <td>3</td>\n      <td>7.8</td>\n      <td>2.0</td>\n      <td>4.2375</td>\n      <td>72.750</td>\n      <td>740.097015</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2015</td>\n      <td>2</td>\n      <td>4</td>\n      <td>8.5</td>\n      <td>-1.2</td>\n      <td>3.0375</td>\n      <td>65.875</td>\n      <td>760.081199</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2015</td>\n      <td>2</td>\n      <td>5</td>\n      <td>7.9</td>\n      <td>-3.6</td>\n      <td>1.8625</td>\n      <td>55.375</td>\n      <td>676.920858</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"execution_count":9}]},{"metadata":{"collapsed":false,"id":"8D6B267650094D51A6BE55FDB8724DA6","scrolled":false},"cell_type":"code","source":"# 查看数据采集区1的数据\nplt.figure(figsize=(24,8))\nfor i in range(8):\n    plt.subplot(8, 1, i+1)\n    plt.plot(data.values[:, i])\n    plt.title(columns[i], y=0.5, loc='right')\nplt.show() ","execution_count":10,"outputs":[{"output_type":"display_data","metadata":{"needs_background":"light"},"data":{"text/plain":"<Figure size 1728x576 with 8 Axes>","text/html":"<img src=\"https://cdn.kesci.com/rt_upload/8D6B267650094D51A6BE55FDB8724DA6/ptls4revt3.png\">"}}]},{"metadata":{"id":"6833B503D652494C802C409877FFCD8A","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"# 观察到DATAC_COL数据的波动，随着季节和年月的变化，具有一定的规律性，称之为季节性；\n# 针对该类型的数据，会有一系列的模型试用，本次结果仅用LSTM模型进行数据预测。时间原因\n#，不进行不同模型结果比较。","execution_count":11},{"metadata":{"collapsed":false,"id":"FF2A3C01524E4FFE981EDD98F7972197","scrolled":false},"cell_type":"code","source":"# 将时间序列问题，转换为有监督的问题。\ndef series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n    n_vars = 1 if type(data) is list else data.shape[1]\n    df = pd.DataFrame(data)\n    cols, names = list(), list()\n    # input sequence (t-n, ... t-1)\n    for i in range(n_in, 0, -1):\n        cols.append(df.shift(i))\n        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n    # forecast sequence (t, t+1, ... t+n)\n    for i in range(0, n_out):\n        cols.append(df.shift(-i))\n        if i == 0:\n            names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n        else:\n            names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n    # put it all together\n    agg = pd.concat(cols, axis=1)\n    agg.columns = names\n    # drop rows with NaN values\n    if dropnan:\n        agg.dropna(inplace=True)\n    return agg","execution_count":12,"outputs":[]},{"metadata":{"collapsed":false,"id":"B0F902C11FE0426789E8B281DB2E05D1","scrolled":false},"cell_type":"code","source":"\n# 将数据归一化到0-1之间,无量纲化，即归一化处理，试用sklearn库中的 MinMaxScaler方法。\n# scaler = MinMaxScaler(feature_range=(0,1))\n# scaled_data = scaler.fit_transform(example[['DATA_COL','TEMP_HIG','TEMP_COL','AVG_TEMP','AVG_WET']].values)\n\nfrom sklearn import preprocessing \nscaler = preprocessing.MinMaxScaler(feature_range=(0,1))\nscaled_data = scaler.fit_transform(data[['DATA_COL','TEMP_HIG','TEMP_COL','AVG_TEMP','AVG_WET']].values)\n# scaled_data = data[['DATA_COL','TEMP_HIG','TEMP_COL','AVG_TEMP','AVG_WET']].values\nprint('归一化后的数据维度：',scaled_data.shape)\nscaled_data[0:5][:]","execution_count":13,"outputs":[{"output_type":"stream","text":"归一化后的数据维度： (578, 5)\n","name":"stdout"},{"output_type":"execute_result","metadata":{},"data":{"text/plain":"array([[0.34896842, 0.04986877, 0.26582278, 0.2126935 , 0.59916493],\n       [0.25282935, 0.16272966, 0.17721519, 0.23684211, 0.63674322],\n       [0.24816014, 0.20472441, 0.32658228, 0.29814241, 0.56158664],\n       [0.26021767, 0.22309711, 0.24556962, 0.26842105, 0.44676409],\n       [0.2100426 , 0.20734908, 0.18481013, 0.23931889, 0.27139875]])"},"execution_count":13}]},{"metadata":{"id":"7F85CBEBD7B24273BEA732F545B7B02D","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"=========================================================\n有监督时间序列数据\n第一栏：当天产值；\n第二到五栏：四个影响因素；\n第六栏：明天产值\n=========================================================\n","name":"stdout"},{"output_type":"execute_result","metadata":{},"data":{"text/plain":"   var1(t-1)  var2(t-1)  var3(t-1)  var4(t-1)  var5(t-1)   var1(t)\n1   0.348968   0.049869   0.265823   0.212693   0.599165  0.252829\n2   0.252829   0.162730   0.177215   0.236842   0.636743  0.248160\n3   0.248160   0.204724   0.326582   0.298142   0.561587  0.260218\n4   0.260218   0.223097   0.245570   0.268421   0.446764  0.210043\n5   0.210043   0.207349   0.184810   0.239319   0.271399  0.263193","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>var1(t-1)</th>\n      <th>var2(t-1)</th>\n      <th>var3(t-1)</th>\n      <th>var4(t-1)</th>\n      <th>var5(t-1)</th>\n      <th>var1(t)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>0.348968</td>\n      <td>0.049869</td>\n      <td>0.265823</td>\n      <td>0.212693</td>\n      <td>0.599165</td>\n      <td>0.252829</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.252829</td>\n      <td>0.162730</td>\n      <td>0.177215</td>\n      <td>0.236842</td>\n      <td>0.636743</td>\n      <td>0.248160</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.248160</td>\n      <td>0.204724</td>\n      <td>0.326582</td>\n      <td>0.298142</td>\n      <td>0.561587</td>\n      <td>0.260218</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.260218</td>\n      <td>0.223097</td>\n      <td>0.245570</td>\n      <td>0.268421</td>\n      <td>0.446764</td>\n      <td>0.210043</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.210043</td>\n      <td>0.207349</td>\n      <td>0.184810</td>\n      <td>0.239319</td>\n      <td>0.271399</td>\n      <td>0.263193</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"execution_count":14}],"source":"# 将时序数据转换为监督问题数据，完成数据转换。\nreframed = series_to_supervised(scaled_data, 1, 1)\n\n#删除无用的label数据，当存在数据NAN时候，将该数据删除。\nreframed.drop(reframed.columns[[6,7,8,9]], axis=1, inplace=True)\nredf = reframed\n\n# print(redf.info())\nprint('=========================================================')\nprint('有监督时间序列数据')\nprint('第一栏：当天产值；\\n第二到五栏：四个影响因素；\\n第六栏：明天产值')\nprint('=========================================================')\nredf.head()\n","execution_count":14},{"metadata":{"collapsed":false,"scrolled":false,"id":"ED5509D7417E4C0585A36F8CA0E06DE5"},"cell_type":"code","source":"# 数据集划分,选取前400天的数据作为训练集,用于训练LSTM模型；\r\n# 将中间150天作为验证集，用于观测训练过程中模型是否出现过拟合；\r\n# 其余的作为测试集，验证模型的测试结果。\r\ntrain_days = 400\r\nvalid_days = 150\r\n\r\nvalues = redf.values\r\n\r\n# 加载训练集、验证集、测试集的数据\r\ntrain = values[:train_days, :]\r\nvalid = values[train_days:train_days+valid_days, :]\r\ntest = values[train_days+valid_days:, :]\r\n\r\n# 训练集和测试集的训练样本X及预测值y。\r\n# X为样本，y为标签。\r\ntrain_X, train_y = train[:, :-1], train[:, -1]\r\nvalid_X, valid_y = valid[:, :-1], valid[:, -1]\r\ntest_X, test_y = test[:, :-1], test[:, -1]\r\n# 训练集的X中包含四百个样本，每个样本包含产量和四个因素共五个数值。\r\ntrain_X.shape, train_y.shape","execution_count":15,"outputs":[{"output_type":"execute_result","metadata":{},"data":{"text/plain":"((400, 5), (400,))"},"execution_count":15}]},{"metadata":{"id":"29182ED8F4814BAE9C4BF8A1A1AF67FC","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"execute_result","metadata":{},"data":{"text/plain":"(array([0.34896842, 0.04986877, 0.26582278, 0.2126935 , 0.59916493]),\n 0.2528293521401861)"},"execution_count":16}],"source":"train_X[0], train_y[0]","execution_count":16},{"metadata":{"collapsed":false,"id":"41C00F2DC77644108A1702C7DEDA4A57","scrolled":false},"cell_type":"code","source":" \r\n# 将数据集重构为符合LSTM要求的数据格式,即 [样本，时间步，特征].\r\n# 在原数据样本上，增加一个维度。使数据格式满足模型的输入、输出格式。\r\ntrain_X = train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))\r\nvalid_X = valid_X.reshape((valid_X.shape[0], 1, valid_X.shape[1]))\r\ntest_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))\r\nprint(train_X.shape, train_y.shape, valid_X.shape, valid_y.shape, test_X.shape, test_y.shape)  \r\n\r\ntrain_y = train_y.reshape((train_y.shape[0], 1, 1))\r\nvalid_y = valid_y.reshape((valid_y.shape[0], 1, 1))\r\ntest_y = test_y.reshape((test_y.shape[0], 1, 1))\r\n\r\nprint(train_X.shape, train_y.shape, valid_X.shape, valid_y.shape, test_X.shape, test_y.shape)","execution_count":17,"outputs":[{"output_type":"stream","text":"(400, 1, 5) (400,) (150, 1, 5) (150,) (27, 1, 5) (27,)\n(400, 1, 5) (400, 1, 1) (150, 1, 5) (150, 1, 1) (27, 1, 5) (27, 1, 1)\n","name":"stdout"}]},{"metadata":{"collapsed":false,"id":"382472E44D2B47838A4BFD49DC9BBCD1","scrolled":false},"cell_type":"code","source":"\r\n# 使用Keras生成LSTM模型，模型包含一个LSTM模块和一个输出。\r\nmodel2 = Sequential()\r\n# LSTM中，激活函数使用relu\r\nmodel2.add(LSTM(50, activation='relu',input_shape=(train_X.shape[1], train_X.shape[2]), return_sequences=True))\r\n# 输出结果的激活函数使用线性函数，不做非线性处理。\r\nmodel2.add(Dense(1, activation='linear'))\r\n# 使用的损失函数为MSE，最小误差方差损失，使用Adam作为优化方法。\r\nmodel2.compile(loss='mean_squared_error', optimizer='adam') \r\n# 显示模型的结构\r\nmodel2.summary()\r\n","execution_count":18,"outputs":[{"output_type":"stream","text":"_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nlstm_1 (LSTM)                (None, 1, 50)             11200     \n_________________________________________________________________\ndense_1 (Dense)              (None, 1, 1)              51        \n=================================================================\nTotal params: 11,251\nTrainable params: 11,251\nNon-trainable params: 0\n_________________________________________________________________\n","name":"stdout"}]},{"metadata":{"id":"5E2F61CE08E94D4288DF8953774129F2","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"display_data","metadata":{"needs_background":"light"},"data":{"text/plain":"<Figure size 432x288 with 1 Axes>","text/html":"<img src=\"https://cdn.kesci.com/rt_upload/5E2F61CE08E94D4288DF8953774129F2/ptls4rkiv.png\">"}}],"source":"# from keras.utils import plot_model\n# plot_model(model2, 'lstm.png')\nfrom PIL import Image\nplt.imshow(np.array(Image.open('lstm.png')))\nplt.axis('off')\nplt.show()","execution_count":19},{"metadata":{"collapsed":false,"id":"B985EB1E5861456A9C7B46C44640C653","scrolled":false},"cell_type":"code","source":"# 训练模型\n# LSTM 是进行时间序列的数据生成预测结果的一个常用深度学习模型，常用于自然语言处理。\n# 在时间序列分析中也发挥着重要作用。\nLSTM = model2.fit(train_X, train_y, epochs=100, batch_size=32, validation_data=(valid_X, valid_y), verbose=2, shuffle=False)\n","execution_count":20,"outputs":[{"output_type":"stream","text":"Train on 400 samples, validate on 150 samples\nEpoch 1/100\n - 1s - loss: 0.0287 - val_loss: 0.0426\nEpoch 2/100\n - 0s - loss: 0.0219 - val_loss: 0.0395\nEpoch 3/100\n - 0s - loss: 0.0197 - val_loss: 0.0386\nEpoch 4/100\n - 0s - loss: 0.0190 - val_loss: 0.0377\nEpoch 5/100\n - 0s - loss: 0.0183 - val_loss: 0.0366\nEpoch 6/100\n - 0s - loss: 0.0177 - val_loss: 0.0356\nEpoch 7/100\n - 0s - loss: 0.0170 - val_loss: 0.0346\nEpoch 8/100\n - 0s - loss: 0.0164 - val_loss: 0.0336\nEpoch 9/100\n - 0s - loss: 0.0158 - val_loss: 0.0326\nEpoch 10/100\n - 0s - loss: 0.0152 - val_loss: 0.0316\nEpoch 11/100\n - 0s - loss: 0.0146 - val_loss: 0.0307\nEpoch 12/100\n - 0s - loss: 0.0140 - val_loss: 0.0297\nEpoch 13/100\n - 0s - loss: 0.0134 - val_loss: 0.0287\nEpoch 14/100\n - 0s - loss: 0.0128 - val_loss: 0.0278\nEpoch 15/100\n - 0s - loss: 0.0123 - val_loss: 0.0268\nEpoch 16/100\n - 0s - loss: 0.0117 - val_loss: 0.0257\nEpoch 17/100\n - 0s - loss: 0.0112 - val_loss: 0.0247\nEpoch 18/100\n - 0s - loss: 0.0106 - val_loss: 0.0236\nEpoch 19/100\n - 0s - loss: 0.0101 - val_loss: 0.0225\nEpoch 20/100\n - 0s - loss: 0.0096 - val_loss: 0.0214\nEpoch 21/100\n - 0s - loss: 0.0090 - val_loss: 0.0203\nEpoch 22/100\n - 0s - loss: 0.0086 - val_loss: 0.0192\nEpoch 23/100\n - 0s - loss: 0.0081 - val_loss: 0.0181\nEpoch 24/100\n - 0s - loss: 0.0076 - val_loss: 0.0170\nEpoch 25/100\n - 0s - loss: 0.0072 - val_loss: 0.0159\nEpoch 26/100\n - 0s - loss: 0.0067 - val_loss: 0.0149\nEpoch 27/100\n - 0s - loss: 0.0063 - val_loss: 0.0138\nEpoch 28/100\n - 0s - loss: 0.0060 - val_loss: 0.0128\nEpoch 29/100\n - 0s - loss: 0.0056 - val_loss: 0.0119\nEpoch 30/100\n - 0s - loss: 0.0052 - val_loss: 0.0110\nEpoch 31/100\n - 0s - loss: 0.0049 - val_loss: 0.0101\nEpoch 32/100\n - 0s - loss: 0.0046 - val_loss: 0.0093\nEpoch 33/100\n - 0s - loss: 0.0043 - val_loss: 0.0085\nEpoch 34/100\n - 0s - loss: 0.0041 - val_loss: 0.0078\nEpoch 35/100\n - 0s - loss: 0.0038 - val_loss: 0.0071\nEpoch 36/100\n - 0s - loss: 0.0036 - val_loss: 0.0065\nEpoch 37/100\n - 0s - loss: 0.0034 - val_loss: 0.0059\nEpoch 38/100\n - 0s - loss: 0.0032 - val_loss: 0.0055\nEpoch 39/100\n - 0s - loss: 0.0031 - val_loss: 0.0051\nEpoch 40/100\n - 0s - loss: 0.0029 - val_loss: 0.0047\nEpoch 41/100\n - 0s - loss: 0.0028 - val_loss: 0.0044\nEpoch 42/100\n - 0s - loss: 0.0027 - val_loss: 0.0042\nEpoch 43/100\n - 0s - loss: 0.0026 - val_loss: 0.0040\nEpoch 44/100\n - 0s - loss: 0.0026 - val_loss: 0.0038\nEpoch 45/100\n - 0s - loss: 0.0025 - val_loss: 0.0037\nEpoch 46/100\n - 0s - loss: 0.0024 - val_loss: 0.0036\nEpoch 47/100\n - 0s - loss: 0.0024 - val_loss: 0.0035\nEpoch 48/100\n - 0s - loss: 0.0024 - val_loss: 0.0035\nEpoch 49/100\n - 0s - loss: 0.0023 - val_loss: 0.0034\nEpoch 50/100\n - 0s - loss: 0.0023 - val_loss: 0.0034\nEpoch 51/100\n - 0s - loss: 0.0023 - val_loss: 0.0034\nEpoch 52/100\n - 0s - loss: 0.0023 - val_loss: 0.0034\nEpoch 53/100\n - 0s - loss: 0.0022 - val_loss: 0.0034\nEpoch 54/100\n - 0s - loss: 0.0022 - val_loss: 0.0034\nEpoch 55/100\n - 0s - loss: 0.0022 - val_loss: 0.0034\nEpoch 56/100\n - 0s - loss: 0.0022 - val_loss: 0.0034\nEpoch 57/100\n - 0s - loss: 0.0022 - val_loss: 0.0034\nEpoch 58/100\n - 0s - loss: 0.0022 - val_loss: 0.0034\nEpoch 59/100\n - 0s - loss: 0.0022 - val_loss: 0.0034\nEpoch 60/100\n - 0s - loss: 0.0022 - val_loss: 0.0034\nEpoch 61/100\n - 0s - loss: 0.0022 - val_loss: 0.0034\nEpoch 62/100\n - 0s - loss: 0.0022 - val_loss: 0.0033\nEpoch 63/100\n - 0s - loss: 0.0022 - val_loss: 0.0033\nEpoch 64/100\n - 0s - loss: 0.0022 - val_loss: 0.0033\nEpoch 65/100\n - 0s - loss: 0.0022 - val_loss: 0.0033\nEpoch 66/100\n - 0s - loss: 0.0021 - val_loss: 0.0033\nEpoch 67/100\n - 0s - loss: 0.0021 - val_loss: 0.0033\nEpoch 68/100\n - 0s - loss: 0.0021 - val_loss: 0.0033\nEpoch 69/100\n - 0s - loss: 0.0021 - val_loss: 0.0033\nEpoch 70/100\n - 0s - loss: 0.0021 - val_loss: 0.0033\nEpoch 71/100\n - 0s - loss: 0.0021 - val_loss: 0.0033\nEpoch 72/100\n - 0s - loss: 0.0021 - val_loss: 0.0033\nEpoch 73/100\n - 0s - loss: 0.0021 - val_loss: 0.0033\nEpoch 74/100\n - 0s - loss: 0.0021 - val_loss: 0.0033\nEpoch 75/100\n - 0s - loss: 0.0021 - val_loss: 0.0033\nEpoch 76/100\n - 0s - loss: 0.0021 - val_loss: 0.0033\nEpoch 77/100\n - 0s - loss: 0.0021 - val_loss: 0.0033\nEpoch 78/100\n - 0s - loss: 0.0021 - val_loss: 0.0033\nEpoch 79/100\n - 0s - loss: 0.0021 - val_loss: 0.0033\nEpoch 80/100\n - 0s - loss: 0.0021 - val_loss: 0.0033\nEpoch 81/100\n - 0s - loss: 0.0021 - val_loss: 0.0033\nEpoch 82/100\n - 0s - loss: 0.0021 - val_loss: 0.0033\nEpoch 83/100\n - 0s - loss: 0.0021 - val_loss: 0.0033\nEpoch 84/100\n - 0s - loss: 0.0021 - val_loss: 0.0033\nEpoch 85/100\n - 0s - loss: 0.0021 - val_loss: 0.0033\nEpoch 86/100\n - 0s - loss: 0.0021 - val_loss: 0.0033\nEpoch 87/100\n - 0s - loss: 0.0021 - val_loss: 0.0033\nEpoch 88/100\n - 0s - loss: 0.0021 - val_loss: 0.0033\nEpoch 89/100\n - 0s - loss: 0.0021 - val_loss: 0.0033\nEpoch 90/100\n - 0s - loss: 0.0021 - val_loss: 0.0033\nEpoch 91/100\n - 0s - loss: 0.0021 - val_loss: 0.0033\nEpoch 92/100\n - 0s - loss: 0.0021 - val_loss: 0.0033\nEpoch 93/100\n - 0s - loss: 0.0021 - val_loss: 0.0033\nEpoch 94/100\n - 0s - loss: 0.0021 - val_loss: 0.0033\nEpoch 95/100\n - 0s - loss: 0.0021 - val_loss: 0.0033\nEpoch 96/100\n - 0s - loss: 0.0021 - val_loss: 0.0032\nEpoch 97/100\n - 0s - loss: 0.0021 - val_loss: 0.0032\nEpoch 98/100\n - 0s - loss: 0.0021 - val_loss: 0.0032\nEpoch 99/100\n - 0s - loss: 0.0021 - val_loss: 0.0032\nEpoch 100/100\n - 0s - loss: 0.0021 - val_loss: 0.0032\n","name":"stdout"}]},{"metadata":{"id":"5E692641FA9847CF84E1EBBCFA118C77","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"# 存储训练结果\nmodel2.save('lstm.h5')","execution_count":21},{"metadata":{"id":"298EB8D41D444F8B82F42A1286F1F51F","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"display_data","metadata":{"needs_background":"light"},"data":{"text/plain":"<Figure size 432x288 with 1 Axes>","text/html":"<img src=\"https://cdn.kesci.com/rt_upload/298EB8D41D444F8B82F42A1286F1F51F/ptls52wqu.png\">"}}],"source":"# plot history\nplt.plot(LSTM.history['loss'], label='train')\nplt.plot(LSTM.history['val_loss'], label='valid')\nplt.legend()\nplt.title('Change of Loss During Training')\nplt.show()","execution_count":22},{"metadata":{"id":"A81F8C2A37214667AF6A7353C2E022AE","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"# 训练过程中，模型未出现过拟合现象，且损失最后收敛。","execution_count":23},{"metadata":{"collapsed":false,"id":"C39FDAD43FC749F09B0B26B29FE3457B","scrolled":false},"cell_type":"code","source":"# 将训练数据作为输入，获取模型预测的输出结果。\r\ntrain_predict = model2.predict(train_X)\r\n# 将验证集数据作为输入，获取模型预测的输出结果。\r\nvalid_predict = model2.predict(valid_X)\r\n# 将测试集数据作为输入，获取模型预测的输出结果。\r\ntest_predict = model2.predict(test_X)\r\n\r\ntrain_predict.shape, test_predict[0:5]","execution_count":24,"outputs":[{"output_type":"execute_result","metadata":{},"data":{"text/plain":"((400, 1, 1), array([[[0.2793009 ]],\n \n        [[0.27093697]],\n \n        [[0.31213573]],\n \n        [[0.2897593 ]],\n \n        [[0.24541068]]], dtype=float32))"},"execution_count":24}]},{"metadata":{"id":"736F6A9E104444F0A69DC4C24FD8E234","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"execute_result","metadata":{},"data":{"text/plain":"(400, 1)"},"execution_count":25}],"source":"# 调整数据的维度，便于进行可视化呈现。\r\ntrain_predict = train_predict.reshape([train_predict.shape[0],1])\r\nvalid_predict = valid_predict.reshape([valid_predict.shape[0],1])\r\ntest_predict = test_predict.reshape([test_predict.shape[0],1])\r\ntrain_predict.shape","execution_count":25},{"metadata":{"collapsed":false,"id":"6A09329B857743FDBE54F88D6F400BA7","scrolled":false,"hide_input":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"collapsed":false,"id":"F6F3BBAC91CC4AF9942A60D97C02DD2C","scrolled":false},"cell_type":"code","source":"plt.figure(figsize=(24,8))\r\nplt.plot(values[:, -1], c='b')\r\nplt.plot([x for x in train_predict], c='g')\r\nplt.plot([None for _ in train_predict] + [x for x in valid_predict], c='y')\r\nplt.plot([None for _ in train_predict] + [None for _ in valid_predict] + [x for x in test_predict], c='r')\r\nplt.legend(['Original data', 'predicted trained data','predicted valid data', 'predicted test data'])\r\nplt.title('Time Series Analysis')\r\nplt.show()","execution_count":26,"outputs":[{"output_type":"display_data","metadata":{"needs_background":"light"},"data":{"text/plain":"<Figure size 1728x576 with 1 Axes>","text/html":"<img src=\"https://cdn.kesci.com/rt_upload/F6F3BBAC91CC4AF9942A60D97C02DD2C/ptls54etav.png\">"}}]},{"metadata":{"id":"7FD879DD5C1B4A9E8A702AF86C8A84C4","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"display_data","metadata":{"needs_background":"light"},"data":{"text/plain":"<Figure size 1728x576 with 3 Axes>","text/html":"<img src=\"https://cdn.kesci.com/rt_upload/7FD879DD5C1B4A9E8A702AF86C8A84C4/ptls55gavv.png\">"}}],"source":"plt.figure(figsize=(24,8))\r\nplt.subplot(3,1,1)\r\nplt.plot(values[:, -1], c='b')\r\nplt.plot([x for x in train_predict], c='g')\r\nplt.legend(['Original data', 'predicted trained data'])\r\nplt.subplot(3,1,2)\r\nplt.plot(values[:, -1], c='b')\r\nplt.plot([None for _ in train_predict] + [x for x in valid_predict], c='y')\r\nplt.legend(['Original data', 'predicted valid data'])\r\nplt.subplot(3,1,3)\r\nplt.plot(values[:, -1], c='b')\r\nplt.plot([None for _ in train_predict] + [None for _ in valid_predict] + [x for x in test_predict], c='r')\r\nplt.legend(['Original data', 'predicted test data'])\r\nplt.show()","execution_count":27},{"metadata":{"collapsed":false,"id":"389C93EA27EA4A9F851A875AB4F884F8","scrolled":false},"cell_type":"code","source":"# 时间原因，只给出模型的结果，结果的误差分析未进行。\n# 本次实验主要目的，是为了验证LSTM在真实场景下的工业数据是否具有良好效果，以及实现模型搭建。","outputs":[],"execution_count":28}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":0}